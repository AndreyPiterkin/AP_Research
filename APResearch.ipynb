{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f6b47c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\python38\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\python38\\lib\\site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\python38\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\python38\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\python38\\lib\\site-packages (from tensorflow) (0.12.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\python38\\lib\\site-packages (from tensorflow) (3.15.7)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in c:\\python38\\lib\\site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\python38\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\python38\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\python38\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: h5py~=2.10.0 in c:\\python38\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\python38\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\python38\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in c:\\python38\\lib\\site-packages (from tensorflow) (1.32.0)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\python38\\lib\\site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: tensorboard~=2.4 in c:\\python38\\lib\\site-packages (from tensorflow) (2.4.1)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\python38\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\python38\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\python38\\lib\\site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\python38\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.28.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\python38\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (0.4.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\python38\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\python38\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\python38\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (41.2.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\python38\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\python38\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\python38\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\python38\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\python38\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\python38\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\python38\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\python38\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: opencv-python in c:\\python38\\lib\\site-packages (4.5.1.48)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\python38\\lib\\site-packages (from opencv-python) (1.19.5)\n",
      "Requirement already satisfied: scikit-image in c:\\python38\\lib\\site-packages (0.18.1)\n",
      "Requirement already satisfied: scipy>=1.0.1 in c:\\python38\\lib\\site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\python38\\lib\\site-packages (from scikit-image) (1.19.5)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\python38\\lib\\site-packages (from scikit-image) (2021.3.31)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in c:\\python38\\lib\\site-packages (from scikit-image) (3.4.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\python38\\lib\\site-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in c:\\python38\\lib\\site-packages (from scikit-image) (2.9.0)\n",
      "Requirement already satisfied: networkx>=2.0 in c:\\python38\\lib\\site-packages (from scikit-image) (2.5.1)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in c:\\python38\\lib\\site-packages (from scikit-image) (8.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python38\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\python38\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\python38\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\python38\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
      "Requirement already satisfied: six in c:\\python38\\lib\\site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in c:\\python38\\lib\\site-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
      "Requirement already satisfied: Pillow in c:\\python38\\lib\\site-packages (8.2.0)\n",
      "Using matplotlib backend: TkAgg\n",
      "Requirement already satisfied: mlxtend in c:\\python38\\lib\\site-packages (0.18.0)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\python38\\lib\\site-packages (from mlxtend) (1.0.1)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\python38\\lib\\site-packages (from mlxtend) (1.2.3)\n",
      "Requirement already satisfied: setuptools in c:\\python38\\lib\\site-packages (from mlxtend) (41.2.0)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\python38\\lib\\site-packages (from mlxtend) (1.19.5)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\python38\\lib\\site-packages (from mlxtend) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.3 in c:\\python38\\lib\\site-packages (from mlxtend) (0.24.1)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\python38\\lib\\site-packages (from mlxtend) (3.4.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\python38\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\python38\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (8.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\python38\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\python38\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python38\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.10.0)\n",
      "Requirement already satisfied: six in c:\\python38\\lib\\site-packages (from cycler>=0.10->matplotlib>=3.0.0->mlxtend) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\python38\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2021.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python38\\lib\\site-packages (from scikit-learn>=0.20.3->mlxtend) (2.1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\python38\\lib\\site-packages (0.11.1)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\python38\\lib\\site-packages (from seaborn) (1.2.3)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\python38\\lib\\site-packages (from seaborn) (1.19.5)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\python38\\lib\\site-packages (from seaborn) (1.4.1)\n",
      "Requirement already satisfied: matplotlib>=2.2 in c:\\python38\\lib\\site-packages (from seaborn) (3.4.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\python38\\lib\\site-packages (from matplotlib>=2.2->seaborn) (8.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\python38\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\python38\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\python38\\lib\\site-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python38\\lib\\site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: six in c:\\python38\\lib\\site-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\python38\\lib\\site-packages (from pandas>=0.23->seaborn) (2021.1)\n",
      "2.4.1\n",
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow\n",
    "!pip3 install opencv-python\n",
    "!pip3 install scikit-image\n",
    "!pip install --upgrade Pillow\n",
    "!pip3 install mlxtend\n",
    "!pip3 install seaborn\n",
    "\n",
    "%matplotlib auto\n",
    "\n",
    "import seaborn as sns\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from mlxtend.evaluate import scoring\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.evaluate import confusion_matrix \n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import matthews_corrcoef, f1_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "import csv\n",
    "from collections import defaultdict, namedtuple\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import imageio\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from IPython import display\n",
    "import shutil\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Reshape\n",
    "from keras.layers import BatchNormalization, Activation, Conv2D, Conv2DTranspose\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6e5860c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"data/train/\"\n",
    "\n",
    "imagesChanged = 0\n",
    "\n",
    "for fileclass in os.listdir(filepath):\n",
    "    if os.path.isdir(filepath+fileclass):\n",
    "        fileclassPath = filepath + fileclass + \"/\"\n",
    "        os.rename(fileclassPath, filepath+\"IMG-\"+fileclass+\"/\")\n",
    "        fileclassPath = filepath+\"IMG-\"+fileclass+\"/\"\n",
    "        for filename in os.listdir(fileclassPath):\n",
    "            if filename.endswith(\".ppm\"): \n",
    "                image = cv2.imread(fileclassPath+filename)\n",
    "                dim = (128,128)\n",
    "                resized = cv2.resize(image, dim)\n",
    "                mask = np.zeros(resized.shape[:2], dtype=\"uint8\")\n",
    "                cv2.rectangle(mask, (0, 0), (96, 128), 255, -1)\n",
    "                masked = cv2.bitwise_and(resized, resized, mask=mask)\n",
    "                filename = \"IMG-\"+filename\n",
    "                cv2.imwrite(fileclassPath+filename, masked)\n",
    "                filename = os.path.splitext(filename)[0]\n",
    "                img = Image.open(fileclassPath+filename+\".ppm\")\n",
    "                img.save(fileclassPath+filename+\".png\",'png')\n",
    "                os.remove(fileclassPath+filename)\n",
    "                print(fileclassPath+filename)\n",
    "                imagesChanged +=1\n",
    "                print(imagesChanged)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4c00f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model = InceptionV3(input_shape= (128,128,3), include_top = False, weights='imagenet')\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('acc')>0.999):\n",
    "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "        \n",
    "\n",
    "x = layers.Flatten()(pre_trained_model.output)\n",
    "\n",
    "x = layers.Dense(1024, activation='relu')(x)                \n",
    "\n",
    "x = layers.Dense  (43, activation='softmax')(x)           \n",
    "\n",
    "model = Model( pre_trained_model.input, x) \n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0003), \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['acc'])\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.)\n",
    "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    \"data/train\",\n",
    "    target_size=(128, 128),\n",
    "    batch_size=30,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    \"data\",\n",
    "    target_size=(128, 128),\n",
    "    batch_size=1,\n",
    "    classes=['test']\n",
    ")\n",
    "\n",
    "callbacks = myCallback()\n",
    "history = model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch = 100,\n",
    "            epochs = 100,\n",
    "            validation_steps = 50,\n",
    "            verbose = 2,\n",
    "            callbacks=[callbacks])\n",
    "np.save('my_history.npy',history.history)\n",
    "model.save(\"InceptionV3_Custom_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c14009a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    \"data/train/\", label_mode=None, image_size=(64, 64), batch_size=32\n",
    ")\n",
    "dataset = dataset.map(lambda x: x / 255.0)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "## Create the discriminator\n",
    "It maps a 64x64 image to a binary classification score.\n",
    "\"\"\"\n",
    "\n",
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(64, 64, 3)),\n",
    "        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1, activation=\"softmax\"),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "discriminator.summary()\n",
    "\n",
    "\"\"\"\n",
    "## Create the generator\n",
    "It mirrors the discriminator, replacing `Conv2D` layers with `Conv2DTranspose` layers.\n",
    "\"\"\"\n",
    "\n",
    "latent_dim = 128\n",
    "\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(latent_dim,)),\n",
    "        layers.Dense(4 * 4 * 128),\n",
    "        layers.Reshape((4, 4, 128)),\n",
    "        layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(128, kernel_size=4, strides=4, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(3, kernel_size=5, padding=\"same\", activation=\"softmax\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")\n",
    "generator.summary()\n",
    "\n",
    "\"\"\"\n",
    "## Override `train_step`\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        # Sample random points in the latent space\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Decode them to fake images\n",
    "        generated_images = self.generator(random_latent_vectors)\n",
    "\n",
    "        # Combine them with real images\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "\n",
    "        # Assemble labels discriminating real from fake images\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "        # Add random noise to the labels - important trick!\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Assemble labels that say \"all real images\"\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Update metrics\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        return {\n",
    "            \"d_loss\": self.d_loss_metric.result(),\n",
    "            \"g_loss\": self.g_loss_metric.result(),\n",
    "        }\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "## Create a callback that periodically saves generated images\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        for i in range(self.num_img):\n",
    "            img = keras.preprocessing.image.array_to_img(generated_images[i])\n",
    "            img.save(\"Generated-Images/generated_img_%03d_%d.png\" % (epoch, i))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "## Train the end-to-end model\n",
    "\"\"\"\n",
    "\n",
    "epochs = 100  # In practice, use ~100 epochs\n",
    "\n",
    "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
    "gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n",
    "    loss_fn=keras.losses.CategoricalCrossentropy(),\n",
    ")\n",
    "\n",
    "hist = gan.fit(\n",
    "    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)]\n",
    ")\n",
    "np.save('my_history_gan.npy',hist.history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99c8d741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39209 images belonging to 43 classes.\n"
     ]
    }
   ],
   "source": [
    "pre_trained_model = InceptionV3(input_shape= (128,128,3), include_top = False, weights='imagenet')\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('acc')>0.999):\n",
    "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "        \n",
    "\n",
    "x = layers.Flatten()(pre_trained_model.output)\n",
    "\n",
    "x = layers.Dense(1024, activation='relu')(x)   \n",
    "\n",
    "x = layers.Dense(172, activation='relu')(x)   \n",
    "\n",
    "x = layers.Dropout(0.1)(x)\n",
    "\n",
    "x = layers.Dense  (43, activation='softmax')(x)           \n",
    "\n",
    "model = Model( pre_trained_model.input, x) \n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['acc'])\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.)\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255.)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    \"data/train\",\n",
    "    target_size=(128, 128),\n",
    "    batch_size=30,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    'data/train',\n",
    "    target_size=(128, 128),\n",
    "    batch_size=30,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "\n",
    "callbacks = myCallback()\n",
    "hist = model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch = 75,\n",
    "            epochs = 100,\n",
    "            validation_steps = 75,\n",
    "            verbose = 2,\n",
    "            validation_data=validation_generator,\n",
    "            callbacks=[callbacks])\n",
    "np.save('my_gan_history.npy',hist.history)\n",
    "model.save(\"GAN_Custom_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6909ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist=np.load('my_gan_history.npy',allow_pickle='TRUE').item()\n",
    "def plot_training(hist):\n",
    "  acc = hist.get('acc')\n",
    "  val_acc = hist.get('val_acc')\n",
    "  loss =  hist.get('loss')\n",
    "  val_loss =  hist.get('val_loss')\n",
    "  epochs = range(len(acc))\n",
    "\n",
    "  plt.plot(acc)\n",
    "  plt.plot(val_acc)\n",
    "  plt.legend(['generator success rate', 'discriminator success rate'], loc='upper left')\n",
    "  plt.title('Training and validation accuracy')\n",
    "  plt.show()\n",
    "  \n",
    "plot_training(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c1a831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1306/1306 [==============================] - 376s 287ms/step\n",
      "0.9416098704762735\n",
      "0.9441141851325279\n",
      "0.9435843811369838\n",
      "0.9426461355886615\n"
     ]
    }
   ],
   "source": [
    "model_remade = keras.models.load_model('InceptionV3-Custom-Model/')\n",
    "\n",
    "Y_pred = model_remade.predict_generator(validation_generator, steps=validation_generator.samples/validation_generator.batch_size,verbose=1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "np.save('results/predictions/y_pred_CNN.npy',y_pred)\n",
    "y_pred=np.load('results/predictions/y_pred_CNN.npy',allow_pickle='TRUE')\n",
    "array = np.arange(43)\n",
    "labels = [\"\".join(\"c\" + str(i)) for i in range(0, 43)]\n",
    "cm = multilabel_confusion_matrix(validation_generator.classes, y_pred, labels=array)\n",
    "\n",
    "def print_confusion_matrix(confusion_matrix, axes, class_label, class_names, fontsize=6):\n",
    "\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\", cbar=False, center=2500, ax=axes,cmap=\"PiYG\",linecolor='black',linewidths=0.5, robust=False)\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    axes.set_ylabel('Actual', fontsize=6)\n",
    "    axes.set_xlabel('Predicted', fontsize = 6)\n",
    "    axes.set_title(\"ConfM for Class \" + class_label, fontsize=8)\n",
    "\n",
    "fig, ax = plt.subplots(7, 7, figsize=(12, 7))\n",
    "    \n",
    "for axes, cfs_matrix, label in zip(ax.flatten(), cm, labels):\n",
    "    print_confusion_matrix(cfs_matrix, axes, label, [\"N\", \"P\"])\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig('results/metrics/cm_CNN.png')\n",
    "\n",
    "mcc = matthews_corrcoef(validation_generator.classes, y_pred)\n",
    "f1_w=f1_score(validation_generator.classes, y_pred, average='weighted')\n",
    "f1_mi=f1_score(validation_generator.classes, y_pred, average='micro')\n",
    "f1_ma=f1_score(validation_generator.classes, y_pred, average='macro')\n",
    "\n",
    "results_GAN = np.array([mcc,f1_w,f1_mi,f1_ma])\n",
    "np.save('results/metrics/cnn-scores.npy', results_GAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba105472",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
